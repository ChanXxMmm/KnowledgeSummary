- [1.JVM与操作系统的关系](#JVM与操作系统的关系)
- [2.JVM运行过程](#JVM运行过程)
- [3.运行时数据区](#运行时数据区)
  - [程序计数器](#程序计数器)
  - [虚拟机栈](#虚拟机栈)
  - [本地方法栈](#本地方法栈)
  - [方法区](#方法区)
  - [Java堆](#Java堆)
  - [从底层深入理解运行时数据区](#从底层深入理解运行时数据区)
  - [内存溢出](#内存溢出)
  - [虚拟机优化技术](#虚拟机优化技术)
- [4.虚拟机中的对象](#虚拟机中的对象)
  - [对象的内存布局](#对象的内存布局)
  - [对象的访问定位](#对象的访问定位)
  - [判断对象的存活](#判断对象的存活)
  - [对象的引用](#对象的引用)
  - [对象的分配策略](#对象的分配策略)
- [5.分代收集理论](#分代收集理论) 
  - [垃圾回收算法](#垃圾回收算法) 
  - [JVM常见的垃圾回收器](#JVM常见的垃圾回收器) 
 
# JVM与操作系统的关系
* 什么是JVM

  JVM -- Java Virtual Machine(Java虚拟机)

* JVM的作用

  JVM的作用就是翻译: 我们平时写的代码都是Java程序，通常是.java后缀，通过javac编译成.class文件，也就是Java字节码，而JVM可以识别字节码的同时还要调操作系统的一些函数，说直白点就是JVM能将字节码翻译成操作系统能够识别的机器码
  
* 跨平台到跨语言
  
  比如我们在接触到的第一个程序HelloWorld.java，它通过javac编译成.class或者打包成jar等，而它在不同操作系统上运行的效果都是一样的，这就是跨平台。
  
  而随着Kotlin的出现，JVM也能够识别Kotlin语言，将它生成的字节码翻译成操作系统能够识别的，当然还有很多其他语言是一样的，这就是跨语言。
  
扩展: JavaSe体系架构
1. JVM只是一个翻译
2. JRE提供了基础类库: 比如io，网络等
3. JDK提供了工具: 比如上面说的将javac工具,反编译用的javap工具等

# JVM运行过程

![image](https://user-images.githubusercontent.com/61224872/111259295-954d1400-8659-11eb-8724-03f6851775eb.png)

* 首先我们编写一个HelloWord.java文件
* 通过javac工具将上述文件编程成HelloWord.class文件，就是上面所说的字节码
* 通过JVM
  * 首先要做的就是通过Java类加载CLassLoader加载到运行时数据区(它就是JVM所管理的内存)中
  * 之后通过JVM中的执行引擎去将运行时数据区中的数据解释执行或者JIT执行操作系统(解释执行可以理解为翻译一行执行一行，JIT可以理解为热点数据，比如一个方法翻译执行了100次，1000次，它就会认为是热点数据，一直是解释执行没有意义，效率很低，它会直接编译成本地代码，提高运行速度)

# 运行时数据区

* 定义:

  Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域

![image](https://user-images.githubusercontent.com/61224872/111259752-8d41a400-865a-11eb-9061-6459d1b33363.png)

我们可以看到运行时数据分可以划分为线程共享和线程隔离/私有的由于多线程的存在

线程私有: 比如三个线程，那么在运行时数据区中，就会有三份线程私有的数据区，分别包含虚拟机栈，本地方法栈，程序计数器。

线程共享: 不受线程影响的有方法区和堆

下面来详细介绍下运行时数据区中的东西:
# 程序计数器
  * 在多线程的环境下，程序计数器负责指向当前线程正在执行的字节码指令的地址
  * 为了方便理解，我们直接上代码
  ```java
  public class Test {
    public Test() {
    }

    public int work() {
        int x = 1;
        int y = 2;
        int z = (x + y) * 10;
        return z;
    }

    public static void main(String[] args) throws Exception {
        Test test = new Test();
        test.work();
    }
  }
  ```
    很简单的一段代码，我们编译下Test类，会在build中生成一个Test.class文件，我们通过javap -c Test.class来看看他的字节码汇编后长什么样:
  ```java
  //我们直接看work方法的样子
  public int work();
    Code:
       0: iconst_1
       1: istore_1
       2: iconst_2
       3: istore_2
       4: iload_1
       5: iload_2
       6: iadd
       7: bipush        10   //大部分指令的偏移量是1，但是如果偏移量过大，就不会是1，比如此时跳过了8
       9: imul
      10: istore_3
      11: iload_3
      12: ireturn
  ```
    我们可以看到我们的程序变成字节码后，有一个Code行号，会按照Code行号从0~12一行一行执行后面的指令，Code表示针对work方法体的偏移量，大体上可以理解为程序计数器记录的地址
  * 可能有人会问了，为什么需要程序计数器？
    因为操作系统的时间轮转机制，程序计数器是针对当前线程而言，如果时间轮转机制将当前线程挂起，当线程再次获得时间片后，程序计数器就保证了下次该执行哪一条指令
  * 程序计数器会OOM吗？
    在JVM内存区域中，程序计数器是唯一不会OOM的，因为它是一块很小的内存区域，它只负责记录刚才我们所说的地址，一般用一个int类型的记录就够了
    
# 虚拟机栈
 
  ![image](https://user-images.githubusercontent.com/61224872/111265527-2fb25500-8664-11eb-996c-35c0a82e8937.png)

  
  * 栈是什么样的数据结构？ FIFO先进后出
  * 虚拟机栈在JVM运行过程中存储当前线程运行方法所需的数据，指令、返回地址
  * 虚拟机栈内部包含栈帧
    * 局部变量表: 存储方法的局部变量(八大数据类型和引用)，比如上面work方法中的x,y,z，比如main方法中的person引用(new Person是对象，Person person中的person就是引用，指向了前面的对象)
    * 操作数栈: 存储方法的操作/执行，我们还是以代码为例
    ```java
     public int work() {
        int x = 1;
        int y = 2;
        int z = (x + y) * 10;
        return z;
    }
    
    public int work();
    Code:
       0: iconst_1           //将int型1入操作数栈，可以理解为创建一个int型变量数值为1加入到操作数栈中
       1: istore_1           //将操作数栈中栈顶int型数值存入到局部变量表下标为1的位置，可以理解为将刚才加入的变量从操作数栈移到局部变量表下标为1的位置(由于不是静态方法，0的位置都是this)，等于上面两步的操作就是 int x = 1;
       2: iconst_2           //将int型2入操作数栈
       3: istore_2           //将操作数栈中栈顶int型数值存入到局部变量表下标为2的位置，等于上面两步的操作就是 int y = 2;
       4: iload_1            //将局部变量表下标为1的数据入操作数栈
       5: iload_2            //将局部变量表下标为2的数据入操作数栈
       6: iadd               //将操作数栈中栈顶两int类型值出栈，相加，并将结果压入操作数栈，等于上面三步完成了 x+y
       7: bipush        10   //将10扩展成int入操作数栈
       9: imul               //将操作数栈栈顶两int数值出栈，相乘，并将结果压入操作数栈，等于完成了(x + y) * 10
      10: istore_3           //将操作数栈中栈顶int型数值存入到局部变量表下标为3的位置
      11: iload_3            //将局部变量表下标为3的数据入操作数栈
      12: ireturn
    ```
    我们可以看到，平时我们所说的栈操作，指的不是虚拟机栈，而是它内部栈帧的操作数栈
    
    * 动态链接: Java语言特性多态，需要类运行时才能确定具体的方法
    ```java
    //比如刚才的Person类如果是个抽象类，他有两个子类Man和Women
    Person tom = new Man();
    tom.work();
    tom = new Woman();
    tom.work();
    ```
    我们可以看到，上端代码在编译器没有任何问题，但是tom无法确定指向Man还是Woman，所在运行期间，就需要动态链接来判断到底是Man还是Woman
    
    * 完成出口: 可以理解为返回地址，比如上面的demo中说的work方法执行完毕，就会打包成一个栈帧携带者z值出栈，此时就会有一个返回地址，也就是方法出口。而具体地址如果方法正常返回则使用程序计数器中的地址作为返回地址，如果异常则要去异常处理表来进行确定
    
# 本地方法栈
本地方法栈保存的是native方法的信息

比如我们的对象都是Object，它都有一个hashCode方法
```java
public native int hashCode();
```
它都会调用底层native方法(内部调用C语言)，当一个JVM创建的线程调用native方法后，JVM不再为其在虚拟机栈中创建栈帧，JVM只是简单地动态链接并直接调用native方法

# 方法区
方法区中存放了类信息，常量，静态变量，即时编译期编译后的代码

* 扩展
1. JDK1.7之前方法区的实现叫永久代，它的划分会跟堆有关系，先根据堆来划分新生代和老年代，再以这样的规范划分了永久代(同时受限于堆的大小)，但是发现JVM不光回收堆，还要回收永久代，但是永久代都是很难回收的，导致回收效率低，所以在JDK1.8之后永久代变为了元空间
2. JDK1.8之后方法区的实现叫元空间，可以直接使用机器内存(直接内存，堆外内存，它不是JVM运行时数据区的一部分，基本是堆中创建一个对象直接引用直接内存)，不再受堆得大小限制,所以它的好处就是方便拓展，但是坏处是会挤压堆大小
3. 任意版本都叫方法区

* 类信息: 就是我们之前所说的Helloworld.class通过类加载器加载到运行时数据区，加载的就是这个类，到方法区中

# Java堆
Java堆中存储着对象实例和数组

可能有人会问为什么方法区和堆中存储的都是共享的数据，为什么要分开呢？因为堆中存储的对象实例和数组都是要被频繁回收的，所以保持不变的和回收难度大的放在了方法区，经常创建和回收的放在了堆，便于垃圾回收的高效

# 从底层深入理解运行时数据区
我们先来看一段代码
```java
public class JVMObject {
    public final static String MAN_TYPE = "man"; 
    public static String WOMAN_TYPE = "woman";  

    public static void  main(String[] args)throws Exception {
        Teacher T1 = new Teacher();
        T1.setName("Mark");
        T1.setSexType(MAN_TYPE);
        T1.setAge(36);
        for (int i=0;i<15;i++){//进行15次垃圾回收
            System.gc();//垃圾回收
        }
        Teacher T2 = new Teacher();
        T2.setName("King");
        T2.setSexType(MAN_TYPE);
        T2.setAge(18);
        Thread.sleep(Integer.MAX_VALUE);//线程休眠很久很久
    }
}

class Teacher{
    String name;
    String sexType;
    int age;

    ......//省略set和get
}
```
上述代码在执行时是如何一步一步的通过JVM进入到运行时数据区的呢？

1. 首先申请内存: 栈内存，堆内存，方法区内存
2. 通过类加载器加载JVMObject.class和Teacher.class，加载到运行时数据区的方法区
3. 方法区加载类后进行拆分，将MAN_TYPE常量和WOMAN_TYPE静态变量放到方法区
4. main方法跑起来后，在虚拟机栈中创建main进程的虚拟机栈，同时在该虚拟机栈中压入main方法的栈帧
5. 执行Teacher T1 = new Teacher()，会在堆Eden区中创建一个T1的Teacher对象，同时在栈帧中的局部变量表中有一个T1的引用
6. 执行set方法: 在栈帧中的操作数栈中不断的入栈出栈
7. 执行15次gc操作，此时垃圾回收器主要对堆进行回收，堆中的T1经历过15次GC后进入到老年代，为什么是15次？在后面的垃圾回收机制中会介绍
8. 执行Teacher T2 = new Teacher()，会在堆Eden区中创建一个T2的Teacher对象，同时在栈帧中的局部变量表中有一个T2的引用
9. 执行set方法: 在栈帧中的操作数栈中不断的入栈出栈

此时JVM的运行时数据区的效果如下图所示:

![image](https://user-images.githubusercontent.com/61224872/111302764-bda33580-868e-11eb-9b12-6b65a8bbaf59.png)

此时我们再通过底层看看JVM的运行时数据区什么样子:
1. 通过jps查看我们这个进程的id，比如我这个id是59079
2. 通过内存可视化工具HSDB来查看下: 
```java
sudo java -cp ,:/Library/Java/JavaVirtualMachines/jdk1.8.0_261.jdk/Contents/Home/lib/sa-jdi.jar sun.jvm.hotspot.HSDB
```
启动HSDB后通过attach我们的进程可以看到

![image](https://user-images.githubusercontent.com/61224872/111305656-2f30b300-8692-11eb-8448-e026d5872c98.png)

上面标识了我们的进程中启动了不同的线程，比如main线程，gc线程等，此时去查看main线程中的虚拟机栈信息

![image](https://user-images.githubusercontent.com/61224872/111305910-82a30100-8692-11eb-96e6-e55edf02fbb4.png)

1. 上图中间一列就是内存地址
2. 我们的main函数还没运行完，表明它的栈帧还在虚拟机栈中，从图中可以看到一行JVMObject.main，说明这个蓝色的就是main栈帧，它会向下延伸一段内存地址，表明这段内存地址都是栈帧
   这就更加说明了虚拟机栈中的栈帧就是对物理地址的虚拟化
3. 我们还可以看到上面还有一个栈帧，因为我们在最后调用了一个线程休眠，它就是Thread.sleep方法的栈帧
4. 我们此时还可以通过这个工具找到我们方法区中的信息，比如搜索我们的全路径，可以找到我们的Teacher类，点进去就可以看到我们创建的T1和T2，再点进去就可以看到他们在的详细信息

![image](https://user-images.githubusercontent.com/61224872/111307778-de6e8980-8694-11eb-9927-10b6d09c3437.png)
![image](https://user-images.githubusercontent.com/61224872/111307929-08c04700-8695-11eb-9f7d-c34fc9047202.png)

里面记录了T1和T2对象的信息和它的地址，我们之前说这两个对象放在了堆中，怎么证明呢？此时再去查看堆上的信息，通过Heap parameters

![image](https://user-images.githubusercontent.com/61224872/111308109-3f965d00-8695-11eb-92d2-e719c3aa337b.png)

我们可以看到堆上新生代(eden区的连续地址，from和to的连续地址)和老年代的连续地址，此时我们可以发现之前的T1在eden区地址内，T2在老年代地址内，这就说明了我们创建的对象在堆中

# 内存溢出
说这个问题前，我们要先知道关于堆栈的空间大小问题，栈的内存要远远小于堆内存，栈的深度是有限制的，可能发生StackOverFlowError问题

* 栈溢出:
  * 在main函数中调用一个方法，该方法无限递归自己，此时就会出现栈溢出，原因就是这个方法也是一个栈帧，它只入栈，没有出栈，导致StackOverFlowError
  * 在内存不多的情况下，大量线程同时跑，可能会造成OOM
2. 堆溢出:
  * 设置堆只有30M大小，直接申请一个35M大小的数组，就会直接导致OOM
  * 设置堆只有30M大小，无限创建对象，就会导致OOM
3. 方法区溢出
  * 设置堆只有10M大小，通过cglib包动态生成编译后的代码，造成OOM
4. 本机直接内存溢出
  * 因为直接内存是我们在使用NIO的时候会用到，所以我们限制直接内存大小100M，直接通过ByteBuffer申请128M内存，造成OOM

如何解决: 通过异常日志找到具体是什么溢出，然后再去检查我们的代码(有点废话)

# 虚拟机优化技术
1. 编译优化技术: 方法内联

直接看代码，比如我们有这么一种情况
```java
public static void main(String[] args){
  boolean x = max(1,2);
}
public static boolean max(int a,int b){
  return a>b;
}
```
我们可以看到main调用max方法会涉及到max栈帧的入栈和出栈，在编译的时候发现如果参数1和2是固定的，就会对其进行优化
```java
public static void main(String[] args){
  boolean x = 1>2;
}
public static boolean max(int a,int b){
  return a>b;
}
```
所以方法内联就是将目标方法的代码原封不动的复制到调用方法中，避免真实的方法调用，减少一次栈帧入栈

2. 栈的优化技术: 栈帧之间的数据共享

两个不同的栈帧的内存区域是独立的，但是大部分的JVM在实现中会进行一些优化，使得两个栈帧出现一部分重叠。（主要体现在方法中有参数传递的情况），让下面栈帧的操作数栈和上面栈帧的部分局部变量重叠在一起，这样做不但节约了一部分空间，更加重要的是在进行方法调用时就可以直接公用一部分数据，无需进行额外的参数复制传递了。

![image](https://user-images.githubusercontent.com/61224872/111314851-c0a52280-869c-11eb-9f7b-ba9b5a036ce0.png)


我们可以看段代码
```java
public class JVMStack{
  public static void main(String[] args){
    JVMStack jvmstack = new JVMStack();
    jvmstack.work(10);
  }
  public static int work(int x){
    int z = (x + 5)*10;
    Thread.sleep(Integer.MAX_VALUE);
    return z;
  }
}
```
我们可以看到10放入了main栈帧中操作数栈中，之后又将它传递给了work栈帧，它会在work栈帧中的局部变量表中，此时我们可以通过HSDB查看

![image](https://user-images.githubusercontent.com/61224872/111314399-555b5080-869c-11eb-9060-2fe252829305.png)


我们可以看到紫色的区域expression stack就是main栈帧的操作数栈，而蓝色一直到黑色的就是work栈帧，其中蓝色最下方的黑色locals area就是work栈帧的局部变量表，此时我们可以看到有一块重合的地址，这个地址就是共享的数据地址

# 虚拟机中的对象
* 虚拟机中的对象的创建过程
 
![image](https://user-images.githubusercontent.com/61224872/111316933-a53b1700-869e-11eb-82e3-3bd8f3852dcd.png)

* 类加载: 通过类加载器加载到内存中
* JVM遇到一条字节码new指令会先进行检查，看是否有对应的模板，比如new A(),会看在方法区中是否可以找到A的符号引用(比如cn.xxx.A)，以及A类是否被加载过，如果失败了则会重新通过类加载一遍
* 如果通过检查，则进行分配内存，一般来说是在堆中间进行分配(也就是堆中的一块地址) 
  * 划分内存的方式是根据堆空间是否规整来判断，而是否规整就要根据垃圾回收器(带不带整理功能)
    * 指针碰撞: 如果在堆的内存中是规整的，这时有个类似指针的东西指向了最后一个对象的一个偏移量，这个时候要创建个新对象要占用一个空间，指针就会移动到下一个空间地址分配给新对象，但是如果要占用多个空间，指针就会移动它所需要的连续空间给到新对象，但是它的前提是堆空间必须规整
    * 空闲列表: 由于JVM垃圾回收器导致堆的内存是不完整的，也就是空闲地址不是连续的，而是零散的，这时候JVM就要维护一个空闲列表，标识各个位置是否可用，此时如果来个新对象需要一个空间，则从空闲列表中找到一个位置的可用空间分配给它，如果是3个空间，则会从空闲列表中找到连续的3个可用空间分配给它
  * 并发安全问题: 在多线程情况下同时申请空间，会发现同一空间可用导致并发安全
    * CAS加失败重试
    * 本地线程分配缓冲: JVM在线程初始化时同时也会在堆中申请一块指定大小的内存，只给当前线程使用，不够的时候再去Eden区申请
* 内存空间初始化: 分配完内存后，虚拟机需要将这块内存空间都初始化为零值(比如int为0，boolean为false等),保证了实例字段在java中不进行赋值也能够直接使用
* 设置: 虚拟机要对对象进行必要的设置,比如对象属于哪个类的实例，如何找到类的元数据信息，对象的hash，gc分代年龄等信息，这些信息会存到对象头中
* 对象初始化: 调用它的构造方法

#  对象的内存布局
![image](https://user-images.githubusercontent.com/61224872/111405639-cf76ee00-870b-11eb-9e24-46aa222df458.png)

可以看到对象可以分为
* 对象头
  * 存储对象自身的运行时数据(Mark Word)
  * 类型指针: 对应的哪个类，指向方法区中的对应的class
  * 若为对象数组，还应有记录数组长度的数据: 
* 实例数据: new一个对象的实例相关数据
* 对齐填充(非必须): 虚拟机对对象大小有要求，必须是8字节的整数，因为对象头和实例数据无法控制，所以对象填充会对他们的总大小进行填充到8字节的整数，而如果他们正好是9字节的整数，则不用对齐填充

# 对象的访问定位
![image](https://user-images.githubusercontent.com/61224872/111419314-37393300-8724-11eb-97ca-5f218e0e7195.png)

* 使用句柄: 在堆中会划分一块区域叫句柄池，在局部变量表中reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。
  * 优点: 对象实例变了，局部变量表中reference还是通过句柄池找
  * 缺点: 对象实例变了，句柄池要进行二次查找，会有一次指针定位的开销
* 直接指针: 在局部变量表中reference中直接直接指向对象实例的地址以及对象类型数据的指针，当对象在堆中的物理地址移来移去，reference都会进行一次改变，避免了二次查找，节约了效率

# 判断对象的存活
* 引用计数法: 
  * 有一个地方引用了这个对象，计数器+1，引用失效时，计数器-1，当计数器=0，表明这个对象没有被引用，它就可以被回收。
  * 问题: 如果两个对象存在相互引用，造成了则一直不能被回收，这就需要一个补偿机制来单独处理这种情况
  * python就是在使用引用计数法
* 可达性分析(根可达):
  * 以GC roots的对象(静态变量，线程栈变量(局部变量表)，常量池，JNI指针,Class，异常，类加载器，加锁synchronized对象等)为起始点，向下寻找引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的
  ```java
  public class Isalive{
    public Object instance = null;
    
    //占据内存，便于判断分析GC
    private byte[] bigSize = new byte[10*1024*1024];
    
    public static void main(String[] args){
    
      Isalive objectA= new Isalive();//objectA在main方法的局部变量表中，说明它在GC Roots上
      Isalive objectB= new Isalive();//objectB在main方法的局部变量表中，说明它在GC Roots上
      
      //相互引用
      objectA.instance = objectB;
      objectB.instance = objectA;
      
      //切断可达，表明局部变量表中的两个引用被清空，堆上的对象不可达了，但是他们的实例变量中的instace还在互相引用
      //说明现在objectA和objectB的instance相互引用，且不在GC Roots的链上
      objectA = null;
      objectB = null;
      
      System.gc();
    }
  }
  ```
  上面的代码可以直观表明GCRoots的一个情况，当两个对象相互引用且不在GC Roots链上时，gc会将其回收掉
* finalize: 即使通过可达性分析判断不可达的对象，也不是“非死不可”，它还会处于“缓刑”阶段，真正要宣告一个对象死亡，需要经过两次标记过程，一次是没有找到与GCRoots的引用链，它将被第一次标记。随后进行一次筛选（如果对象覆盖了finalize），我们可以在finalize中去拯救,但是不可靠，未必会调用！
  
  
# 对象的引用
* 强引用: = 如果局部变量表还存在，那么这个对象就一定在GC Roots链上
* 软引用: 系统即将发生OOM，软引用对象会被回收掉，多用于存bitmap
* 弱引用: gc回收时就会被回收掉,多用于缓存
* 虚引用: 随时被回收掉

# 对象的分配策略

![image](https://user-images.githubusercontent.com/61224872/111428154-1677da00-8732-11eb-8691-c7d315a34189.png)

* new出一个对象，先判断是否栈上分配，判断的标准是否满足逃逸分析(对象会不会被外部引用，不被引用则满足)，满足则进入栈上分配
* 如果不满足线上分配，则判断是否有本地线程分配缓冲(TLAB，1%大小)，如果有则直接使用
* 如果没有则判断是否是大对象(很长的字符串，数组等)，如果是大对象直接进入老年代
  * 老年代比新生代大，比如堆一共30M，老年代会占2/3的大小20M，新生代中eden区8M，from和to都是1M 
  * 避免了在新生代中不断地挪移
* 如果不是大对象则进入Eden区 
* 由于Eden区只存放新生对象，当Eden区的对象越来越多，会触发垃圾回收(空间不足)，在新生代的gc叫Young GC，此时如果大部分对象被回收移出eden区，其中有个对象没有被回收，那么它就会进入到from或者to区，这时会在该存活对象的对象头中的GC分代年龄age+1
* 当Eden区发生不断进入对象，导致gc，就会不断的有存活对象和from或者to区遗留的对象进入到to或者from区，同时对象头中的age+1
* 如果一个对象持续的在from和to中移来移去(新生代采用复制回收算法)没有被回收，当它的age到达15次，则进入到老年代
  * 为什么还要有Eden区？因为通过研究表明，90%的对象在第一次垃圾回收时被回收，只有10%存活，同时复制回收算法需要对等空间，这也就是为什么from和to都是占据新生代的10%，这也就说明了为什么新生代中是8:1:1的分配,这么做完后我们浪费的空间也就只有10%
  * 为什么是15次？因为对象头底层实现上默认都是用4位bits存储，所以最大15(1111)
* 如果一次gc后，from和to都满了，新的对象没有地方去了，此时由于有空间分配担保，所以直接进入到老年代
* 空间分配担保: 当从新生代将对象给到老年代或者给老年代分配大对象时，一定保证空间足够吗?所以有一个悲观策略，每次对象进入到老年代都要进行一次full GC,但是JVM认为这么做很没有效率，每次都要回收，所以就有了一个空间分配担保
  * 对象进入到老年代不用管空间够不够，JVM来担保，如果真的不够了那就再来触发full gc
  * 避免了每次对象进入到老年代都要触发回收
* 动态年龄判断: 为了更好地让from和to区适应，假如from或者to区大小为5M，当它们相同年龄所有对象大小的总和占用了超过一半的空间大小，则会使大于或者等于它们年龄的对象提前进入老年代，无需等到15次

# 分代收集理论
通过各种经验以及验证等，总结得到两条理论:
1. 绝大部分的对象都是朝生夕死
2. 对象熬过多次垃圾回收，那么它越难回收 

所以根据以上两个理论得出应该把这两种对象分开，也就有了新生代和老年代
![image](https://user-images.githubusercontent.com/61224872/111448183-1f27da80-8749-11eb-9a51-483a69c4e14c.png)

上图大部分的东西都在对象分配策略中介绍过，但是有几个点要补充:
1. 垃圾回收器也是一个线程，他针对的是方法区和堆
2. 老年代的回收叫做Major GC或者Old GC
3. Full GC是针对整个堆和方法区的,毕竟方法区也会有内存不足的时候
4. 新生代垃圾回收算法采用复制算法，老年代垃圾回收算法采用标记清除和标记整理算法

# 垃圾回收算法
* 复制算法: 将空间一分为二，只使用一半使用区域，另一半用于复制，当可用区域不够时，进行可达性分析将不可达的移除，剩下的对象移动到另一块区域作为可用区域，之后清除当前区域用作之后的复制区域
  * 特点:
    * 实现简单，运行高效
    * 内存复制，没有内存碎片
    * 利用率只有一半
  * Eden区来源
    * 根据研究表明新生代98%的对象都会被回收，只有2%的对象被保留，所以会给Eden区划分一块很大的区域，同时没有必要给from和to分配太大的空间，所以默认分配8:1:1
  
* 标记清除算法: 首先标记出所有需要回收的对象(不可达)，在标记完成后统一回收所有被标记的对象。
  * 这时候内存区域中就会出现内存碎片(空间不连续)，当再来一个大对象时，由于没有连续的空间分配导致无法给新对象分配空间，会导致提前再次GC
  * 执行效率不稳定: 每次都要先标记，如果空间中90%的对象都是要清理的，执行效率就会很低，要把90%的对象进行标记，清除等操作，如果10%的对象就会很效率，所以适合老年代，因为能到老年代的基本都是经历过很多次垃圾回收，很难回收的

* 标记整理算法: 由于标记清除会有内存碎片问题，所以JVM提出了标记整理算法，就是比标记清除多了一步操作，就是最后将不可回收对象整理一端的连续区域
  * 特点:
    * 没有内存碎片
    * 对象移动，所以效率偏低: 因为老年代大量的对象都不可回收
    * 引用更新: 由于虚拟机采用直接引用，所以栈中的引用也要更新地址
    * 用户线程暂停: 由于引用更新，所以用户线程肯定要访问新的地址，所以要暂停线程

# JVM常见的垃圾回收器
![image](https://user-images.githubusercontent.com/61224872/111475341-f06d2c80-8767-11eb-9876-224b58f7e349.png)

* 单线程回收器:
  * Serial和Serial Old: 由于最早开始内存不是很大，就采用单线程收集器
    * Serial负责新生代，采用复制算法
    * Serial Old负责老年代，采用标记整理算法
    * 虽然是单线程，但是无论是在新生代还是老年代都会STW(stop the world)暂停用户线程，因为要避免有新的对象进入新生代和老年代
  
* 多线程并行收集器:  
  * Parallel Scavenge和Parallel Old: 随着内存的不断增大，就采用了并行的多线程收集器
    * Parallel Scavengel负责新生代，采用复制算法
    * Parallel Old负责老年代，采用标记整理算法
    * 虽然是并行多线程，但是无论是在新生代还是老年代都会STW(stop the world)暂停用户线程，因为要避免有新的对象进入新生代和老年代
    * 同时Parallel Scavenge还可以配合Serial使用
   
  * ParNew: 负责新生代，采用了并行的多线程收集器
    * 和Serial基本没区别，唯一的区别：多线程，多CPU的，停顿时间比Serial少
    * 同时ParNew还可以配合Serial Old使用
    
* 多线程并发收集器: 在清理中，可以不暂停用户线程，会将用户线程和回收线程共享一部分，但不是说全都不暂停和全程暂停，只是部分的时间，用户线程和回收线程可以同时工作(并发)
  * CMS: 我们发现多线程并行的工作还是不能满足或者还要STW(造成用户线程卡顿),就有了CSM
    * 它只针对老年代把标记清除分为几步
      * 初始标记: 会STW，标记GC Roots的直接引用对象，速度很快，因为本身符合GC Roots的存活对象就不会很多
      * 并发标记: 用户线程和GC线程同时运行，时间会长，因为需要标记在GC Roots链上的存活对象，比如只允许4个线程，当4个线程都是用户线程时，CMS只会暂停一个用户线程用来跑回收线程进行标记，不影响其他用户线程
      * 重新标记: 由于并发标记阶段用户和gc线程同时运行，会有新的对象进入老年代，所以此时要STW，对新进来的对象进行重新标记或者对并发中修改过的对象重新标记，所以这个时间很短
      * 并发清理: 用户线程和GC线程同时运行，时间会长，因为要清理标记的对象，此时也会占用一条线程来进行清理
      * 重置线程: 清理结束后，将线程重置，让用户线程继续执行
    * 优点: 只有两次短暂的STW
    * 缺点: 
      * CPU敏感: 因为无论是单线程还是并行多线程，CPU只是单一的去做一个事情，但是CMS中既要完成用户线程，也要做标记清除操作
      * 浮动垃圾: 并发清理阶段，可能还会有新的对象进来，这部分对象就称为浮动垃圾，只能等到下次回收，但是如果浮动垃圾过多就会转换为Serial Old
      * 内存碎片: 由于使用的标记清除，就会有内存碎片，如果碎片过多导致对象无法进入，就会转换为Serial Old
    * 弊端: 当被切换为Serial Old单线程操作，就导致效率很低和卡顿(所以很早的网络游戏都会写个定时重启任务在凌晨维护，就是为了重启解决碎片问题，比切换到Serial Old要效率得多)
    * 同时CMS还可以配合Serial,ParNew使用，当然还可以切换为Serial Old

  * G1
    
 




