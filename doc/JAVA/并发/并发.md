- [1.基础概念](#基础概念)
- [2.线程](#线程)
- [3.线程的生命周期](#线程的生命周期)
- [4.线程间的共享](#线程间的共享)
  - [synchronized内置锁](#synchronized内置锁)
  - [volatile](#volatile)
  - [ThreadLocal](#ThreadLocal)
- [5.线程间的协作](#线程间的协作)
- [6.死锁](#死锁)
- [7.CAS原理](#CAS原理)
- [8.线程池](#线程池)
- [9.AQS](#AQS)
- [10.CLH](#CLH)
- [11.ReentrantLock](#ReentrantLock)
- [12.JMM](#JMM)

# 基础概念
* 什么是进程和线程
  * 进程是程序运行资源分配的最小单位
  * 线程是CPU调度的最小单位,必须依赖于进程而存在

* CPU时间片轮转机制(RR调度)
  * 每个进程被分配一个时间段,称作它的时间片,即该进程允许运行的时间。
  * 如果在时间片结束时进程还在运行,则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束,则CPU当即进行切换。调度程序所要做的就是维护一张就绪进程列表,当进程用完它的时间片后,它被移到队列的末尾 
  * 进程切换也叫上下文切换，很耗费CPU时间，所以尽量避免上下文切换
  * 时间片设得太短会导致过多的进程切换,降低了CPU效率: 而设得太长又可能引起对短的交互请求的响应变差。将时间片设为100ms通常是一个比较合理的折衷。

* 高并发编程
  * 意义: 由于多核多线程的CPU的诞生,多线程和高并发的编程越来越受重视和关注 
  * 好处:
    * 充分利用CPU资源: 在多核CPU下，只有多线程才能充分利用CPU资源
    * 加快响应用户的时间: 多个线程比单线程速度要快
    * 可以使代码模块化，异步化和简单化: 比如多步骤情况下，避免单线程增加等待时间，使用多线程，异步执行
  * 注意事项:
    * 安全性: 由于线程之间共享进程资源，肯定就会存在争夺等问题，这就是线程安全问题
    * 线程之间的锁问题: 为了解决安全问题引入了锁，但是会产生死锁，也会产生锁竞争导致性能下降，没准还不如单线程速度快
    * 线程过多: 线程的数量是有限的，不是无穷无尽的，由操作系统限制，线程过多有可能造成系统创建大量线程而导致消耗完系统内存以及CPU的“过渡切换”,造成系统的死机，所以可以使用线程池

# 线程
Java里的程序天生就是多线程的，一个Java程序都要从main()方法开始，它就是我们常说的main线程，同时还会启动很多其他线程

* 线程的启动与中止
  * 线程的启动方式
    * 继承扩展Thread类，重写run方法
    * 实现Runnable接口，实现run方法
    * Thread和Runnable的区别: Thread是线程的抽象，Runnable是任务的抽象
  * 线程的停止
    * stop(): 强制停止线程，不会关心资源是否释放，不建议使用
    * suspend(): 将线程挂起，强制进行上下文切换，但是不会关心资源是否释放，不建议使用
    * interrupt(): 将线程中断，但只是改变一个中断标志位，未必会中断，要配合isInterrupted()使用(当线程睡眠中被中断，会抛出中断异常，同时重置标志位，需要在异常中修改标志位)
    * isInterrupted(): 返回线程是否被中断
    * interrupted(): 静态方法，返回线程是否被中断，但是会将标志位重置
  * 线程start与run区别:
    * start: 将线程加入到CPU时间片轮转机制的进程列表中等待分配执行
    * run: 只是在调用run方法的线程里执行这个任务而已

# 线程的生命周期
![image](https://user-images.githubusercontent.com/61224872/112082106-be245a80-8bbf-11eb-9949-8877e986ac17.png)

* 新建: new Thread(),此时还是一个类的实例
* 新建-运行: 当调用start()后，线程进入运行状态
* 就绪-运行中: 
  * 当时间片轮转分配该线程时间片后 该线程才进入到运行状态
* 运行中-就绪: 
  * 时间片到期，该线程进入到就绪状态
  * yield(): 调用yield()后让出时间片，该线程进入到就绪状态，不释放锁
* 运行-终止:
  * 线程跑完了，该线程进入到终止状态
  * stop(): 调用stop()后，该线程进入到终止状态
  * setDeamon(): 设置为守护线程，当线程所在的进程中所有非守护线程(用户线程)死亡后，该线程会进入到死亡状态，它内部的finally不一定起作用，比如垃圾回收器线程，主要是调度工作
* 运行-阻塞:
  * synchronized: 调用synchronized没有拿到锁后进入到阻塞状态 
* 阻塞-运行:
  * synchronized: 调用synchronized拿到锁后进入到运行状态
* 运行-等待:
  * wait(): wait()后，线程进入到等待状态，释放锁
  * join(): 调用join()后，该线程才进入到等待状态
  * LockSupport.park(): 调用Lock.lock()没有拿到锁进入到等待状态
* 等待-运行:
  * notify()/notifyAll(): 当其他线程调用notify()/notifyAll()后，通知该线程进入到运行状态，准备重新抢夺锁,不释放锁，只有等到后续逻辑结束后才自动释放锁，notify会随机唤醒一个
  * LockSupport.park(): 调用Lock.lock()没有拿到锁进入到等待状态
* 运行-等待超时
  * sleep(long): sleep()后，该线程进入到等待超时状态，将线程挂起不再进行分配cpu和资源，不释放锁，直到等待超时后进入到运行状态
  * wait(long): wait()后，线程进入到等待超时状态，释放锁，直到被唤醒或者等待超时后进入到运行状态
  * join(long): 调用join(long)后，该线程才进入到等待超时状态，直到等待超时后进入到运行状态

* 线程的优先级:
```java
new Thread().setPriority(5);
```
线程优先级从1-10，默认为5，值越大表明越可能分配的时间片多，取决于底层

# 线程间的共享 
多个线程访问同一个资源，如果不作任何控制，则会出现线程同步问题或者线程不安全问题

# synchronized内置锁
保证在某一时刻，只有一个线程访问同一个资源，保证了可见性和原子性

* 对象锁
  * 对同步块加锁
  ```java
  private Object obj = new Object();
  public void method(){
    synchronized(obj){  //与synchronized(this)相同，不过前者是锁obj对象，后者是锁该类的对象
      //doSomething
    }
  }
  ```
  * 对方法加锁
  ```java
  public synchronized void method(){//等同于synchronized(this)
      //doSomething
  }
  ```
* 类锁: 静态方法上,等于是锁的类的Class
```java
private static Object obj = new Object();
private static void method(){
  synchronized(obj){//锁的是Object.class
   //doSomething
  }
}
```
注意: 如果锁的是常量，比如int类型的常量，在锁内部对它进行i++,则会导致错误的加锁，因为i++会创建新的对象，导致锁的不是一个对象，所以用sychronized加锁时要保证对象不会变化

* synchronized原理
  * 锁代码块: 在编译成class文件后，会对synchronized锁的代码块前后加入monitorenter和monitorexit,而我们经常说的拿对象，拿的就是monitor对象的所有权
  * 锁方法: 在编译成class文件后，会对synchronized锁的方法中的属性中加入ACC_SYNCHRONIZED,而底层的实现也是通过monitorenter和monitorexit
  
* synchronized锁的存放位置
  
  我们知道在我们的对象头中有个MarkDown，内部记录了关于对象头的信息，比如GC年龄，锁信息等，而随着锁的加入，MarkWord中的信息也发生变化，不同的锁状态对应着不同的记录存储方式 

* synchronized锁优化(锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率)
  * 无锁状态: 
  * 偏向锁:
  * 轻量级锁: 
  * 重量级锁: 


# volatile

volatile关键字，最轻量的同步机制，它只保证可见性，所以适用于一写多读的场景

* 防止重排序
  * 后面如果是volatile写操作，则即便前面是普通写操作，为了保证主存数据是后面操作的结果，所以不能重排序
  * 前面如果是volatile读操作，因为后面的普通写操作可能会刷新主存，为了保证百分百执行结果的正确，则也不能重排序

* volatile原理

会在汇编之前将由volatile修饰的变量前加入Lock前缀指令，强迫处理器将数据写回到系统内存中，同时这个写回内存的操作会使其他线程里缓存了该内存地址的数据无效

# ThreadLocal

为每一个线程提供了一个变量副本，这就形成了线程隔离

* ThreadLocal使用:
```java
private ThreadLocal<Integer> threadlocal = new ThreadLocal<Integer>(){
  @Override
  protected Integer initialValue(){
    return 1;//返回默认值
  }
}
Integer i = threadlocal.get()
i = i++;
threadlocal.set(i);
```

* ThreadLocal解析
```java
//Thread.class
//每个线程中有一个ThreadLocal.ThreadLocalMap的成员变量
ThreadLocal.ThreadLocalMap threadLocals = null;


//ThreadLocal.class
static class ThreadLocalMap {
        static class Entry extends WeakReference<ThreadLocal<?>> {
            Object value;
            
            //以不同泛型的具体类型的ThreadLocal为key，以存的值为value
            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }
        
        //由于Entry的key是泛型的ThreadLocal，所以一个线程中可以有多个类型的ThreadLocal存在数组中
        private Entry[] table;
         
        //......
}

//ThreadLocal.class
public T get() {
        //1.拿到调用该方法所在的线程
        Thread t = Thread.currentThread();

        //2.通过线程t拿到该线程独有的ThreadLocalMap
        ThreadLocalMap map = getMap(t);
        
        //如果map不为空，以ThreadLocal为key去拿value
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        //如果map为空或者map中没有，则创建一个以默认值为value的Entry保存到map中并返回
        return setInitialValue();
}

```

* 引发内存泄漏的原因
```java
//ThreadLocalMap
 static class Entry extends WeakReference<ThreadLocal<?>> 
```
我们知道ThreadLocalMap中的Entry是用的弱引用(对对象的引用不了解可以去[JVM](../../JVM/JVM.md)中对象的引用中学习)来保存ThreadLocal<?>，而每个线程中都有一个ThreadLoaclMap保存ThreadLocal<?>和value，当发生垃圾回收时，ThreadLocal<?>就被回收，但是value此时还依旧保存在ThreadLocalMap中，这就是导致内存泄漏的原因，(虽然每次调用get或者set的时候都会将map中key被回收了的value清除)，所以每次使用完Threadlocal时一定要调用它的remove方法(从ThreadLocalMap中清除该线程的ThreadLoacl<?>)

那为什么不用强引用呢？我们知道map中保存着key，这个key指向了堆中的ThreadLoacl对象，当垃圾回收的时候回收的是堆中的对象，也就是new ThreadLocal，此时map中的key依旧保存，所以使用弱引用还有机会在调用set或者get方法的时候将key为null的Entry清除，如果使用强引用则没有任何机会，除非手动清除

* 线程不安全
如果多个线程来保存一个静态变量，则会线程不安全，因为线程中的ThreadLoacl保存的是同一份对象实例的引用(静态变量)，解决的话要么是保存非静态变量，要么是在创建ThreadLoacl的时候给一个默认值

# 线程间的协作
* 等待和通知(wait(),notify(),notifyAll())--[生产消费者模式](../../设计模式/生产消费者模式.md)
* wait(),notify(),notifyAll()是Object的方法，要在synchronized锁包裹内
 
等待的标准范式
 ```java
  syn(对象){
    while(条件不满足){
      对象.wait();
    }
    //业务逻辑
  }
  ```
通知的标准范式
 ```java
  syn(对象){
    //业务逻辑中改变条件
    对象.notify/notifyAll()
    //doSomething...
  }
  ```
我们可以看到，只有在运行完doSomething后，通知才会释放锁，这时候等待才能够唤醒重新去争夺锁资源,所以一般对象.notify/notifyAll()都放在最后

# 死锁
死锁是指两个或者两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞状态，若无歪理作用，它们都将无法推进下去

* 死锁的四个条件
  * 互斥条件: 资源被一个进程占用，其他进程请求资源需要等待
  * 请求和保持: 本持有一个资源，又要去请求新的资源，而该资源被其他进程占有，此时请求进程阻塞，本身资源保持不放
  * 不剥夺条件: 进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放
  * 环路等待条件: A拿a资源，B拿b资源，A要拿b，B要拿a，各自不放手，进行阻塞环形等待
* 避免死锁
  * 内部通过顺序比较，确定拿锁的顺序 
  * 采用尝试拿锁的机制
* 活锁
  * 两个线程在尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生同一个线程总是拿到同一把锁，在尝试拿另一把锁时因为拿不到，而将本来已经持有的锁释放的过程
  * 解决办法: 每个线程休眠随机数，错开拿锁的时间
* 线程饥饿: 低优先级的线程，总是拿不到执行时间

# CAS原理
CAS--Compare And Swap,JDK基于CAS实现了很多原子变量

* 原理
  * get变量值(旧值)
  * 计算后得到新值
  * compare内存中变量值和旧值是否相等，相等则替换旧值为新值，不同则再从头来一次 
* 问题
  * ABA问题: 假设线程A想将一个变量由a改为b，此时有个线程B更快的将a改为c，又从c改为a，这时候A才去比较旧值进行替换，但对于A来说它是不知道B改过a的，可以增加版本戳解决
  * 性能问题: 如果一直失败则一直自旋，导致CPU执行开销大
  * 只能保证一个共享变量的原子操作: 可以将多个对象包装成一个对象或者使用锁


# 线程池
* 好处: 

1. 降低资源消耗: 通过反复利用已创建的线程降低线程创建和销毁造成的消耗
2. 提高响应速度: 当任务到达时，任务可以不需要等到线程创建就能立即执行
3. 提高线程可管理性: 线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。

* 线程池创建各个参数含义:

1. corePoolSize: 核心线程数
2. maximumPoolSize: 最大线程数，表示当前线程池允许的最大线程数
3. keepAliveTime和TimeUnit: 空闲线程的存活时间和单位，默认下只有在线程数大于核心线程数时才有用
4. workQueue: 阻塞队列,当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。通过workQueue，线程池实现了阻塞功能。
5. threadFactory: 可以在创建每个线程的时候做一些额外工作，比如设置线程名字，设置线程为守护线程等
6. handler: 拒绝策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务
   1. AbortPolicy：直接抛出异常，默认策略
   2. CallerRunsPolicy：用调用者所在的线程来执行任务
   3. DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务
   4. DiscardPolicy：直接丢弃任务
   5. 自定义饱和策略，如记录日志或持久化存储不能处理的任务
   
* 线程池的工作机制:
1. 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务
2. 如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。
3. 如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务。
4. 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法

* 提交任务
  * execute(Runnable): 提交不需要返回值的任务
  * submit(Future):  提交需要返回值的任务

* 关闭线程池
  * shutdown: 尝试中断所有没有正在执行任务的线程
  * shutdownNow: 尝试中断所有的线程

* 合理配置参数
  * 最大线程数
    * CPU密集型(计算): 线程数依赖机器的核心线程数+1 Runtime.getRuntime().availableProcessors()
    * IO密集型(读写磁盘/网络): 程数依赖机器的核心线程数*2
    * 混合型: 如果两个花费时间差不多则进行拆分为两个线程池，否则谁花费多就用哪种
  * 阻塞队列: 尽量使用有界队列增加稳定性，无界会收到系统的约束，过多会OOM

# AQS
AbstractQueuedSynchronized----抽象同步队列器

是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量state表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作，采用了[模板方法模式](../../设计模式/模板方法模式.md)，所以在同步工具类的内部，都要通过内部类实现AQS的功能

比如想实现一个独占的就实现tryAcquire方法，想实现一个分享的就实现tryAcquireShared方法

# CLH
* CLH思想
凡是要排队的线程，打包成一个QNode(当前线程，前驱结点和locked)，以链表的形式排队，前驱结点指向前一个QNode的locked，通过类似CAS的机制不断去自旋看前一个节点是否释放锁，比如A线程拿到了锁，其locked为false，这时候来了一个B线程打包成QNode添加到尾结点，指向A，当发现A线程的locked从false变为了true，说明A释放了锁，此时B就去拿锁，拿到锁将自己的locked改为false

之前说的AQS就是基于CLH队列锁的思想的变体实现
* AQS是双向链表
* 不会一直自旋，自旋一定次数后就让线程进行阻塞

# ReentrantLock

* 锁的可重入: 任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞
  * 线程再次获取锁: 锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取
  * 锁的最终释放: 锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。


* 公平和非公平锁:
  * 公平: 如果没有等待排队的则直接尝试拿锁，如果有排队的则去排队
  * 非公平: 不管有没有排队的先CAS去拿一次看看

# JMM
* JMM---Java内存模型
  * 主内存: 线程之间的共享变量存储在主内存
  * 工作内存: 每个线程都有一个私有的本地内存,本地内存中存储了该线程以读/写共享变量的副本

* JMM导致的并发安全问题: 
```java
count = count + 1;
```
如果两个线程同时对count进行操作，在他们的工作内存中都会缓存一份count变量，分别在自己的私有工作内存中进行操作后再写回主内存，等于是都将count为1写入，但是理论上来讲两个线程操作，主内存中的count应该为2，这就产生了并发线程不安全问题。
* 可见性: 当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值
* 原子性: 一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行

所以要解决这两个问题，不光要满足可见性(因为上面的计算过程不是一条语句)，还要满足原子性，所以通过加锁可以解决这个问题并发问题






